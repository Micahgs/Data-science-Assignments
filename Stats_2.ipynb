{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Estimation And Confidence Intervals\n",
        "\n",
        "Data:- A total of 15 print-heads were randomly selected and tested until failure. The durability of each print-head (in millions of characters) was recorded as follows:\n",
        "1.13, 1.55, 1.43, 0.92, 1.25, 1.36, 1.32, 0.85, 1.07, 1.48, 1.20, 1.33, 1.18, 1.22, 1.29\n"
      ],
      "metadata": {
        "id": "hefZdBXPjbJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [1.13, 1.55, 1.43, 0.92, 1.25, 1.36, 1.32, 0.85, 1.07, 1.48, 1.20, 1.33, 1.18, 1.22, 1.29]\n"
      ],
      "metadata": {
        "id": "iu9t3hMWjuKM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A) Build 99% Confidence Interval Using Sample Standard Deviation\n",
        "\n",
        "Assuming the sample is representative of the population, construct a 99% confidence interval for the mean number of characters printed before the print-head fails using the sample standard deviation. Explain the steps you take and the rationale behind using the t-distribution for this task.\n"
      ],
      "metadata": {
        "id": "2USgwiIZj8h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "#given sample data\n",
        "data = [1.13, 1.55, 1.43, 0.92, 1.25, 1.36, 1.32, 0.85, 1.07, 1.48, 1.20, 1.33, 1.18, 1.22, 1.29]\n",
        "n = len(data)\n",
        "mean = np.mean(data)\n",
        "std_dev = np.std(data, ddof=1)  # Sample SD\n",
        "\n",
        "# t-critical value\n",
        "t_crit = stats.t.ppf(0.995, df=n-1)\n",
        "\n",
        "# ME\n",
        "margin_of_error = t_crit * (std_dev / np.sqrt(n))\n",
        "\n",
        "# Ci\n",
        "ci_lower = mean - margin_of_error\n",
        "ci_upper = mean + margin_of_error\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Lolets wer extrem {ci_lower}\\n Upper extreme {ci_upper}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcK6gVUGjieP",
        "outputId": "6db11ba4-c618-44c2-d8e3-bb2b40c7ef45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lolets wer extrem 1.0901973384384906\n",
            " Upper extreme 1.3871359948948425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of Steps and Why I Used the t-distribution\n",
        "\n",
        "1: Calculated the basics\n",
        "I started by finding the mean and sample standard deviation of the given data (15 print-heads). Since this was a destructive test, the sample size was small, just 15 values.\n",
        "\n",
        "2: Used the t-distribution\n",
        "I used the t-distribution instead of the normal (z) distribution because:\n",
        "\n",
        "The sample size is small (less than 30),\n",
        "\n",
        "we don’t know the population standard deviation, only the sample one.\n",
        "\n",
        "This is the standard rule — if Populqtion SD is unknown and the sample is small, we use t-distribution to be on the safer side. It has wider tails, which just means it gives a bigger margin for error when we’re less certain.\n",
        "\n",
        "3: Found the t-critical value\n",
        "Using Python’s scipy.stats.t.ppf function (or I could have used a table), I got the t-critical value for a 99% confidence level and 14 degrees of freedom (n - 1).\n",
        "\n",
        "4: Calculated the margin of error\n",
        "Then, I plugged everything into the margin of error formula\n",
        "\n",
        "5:Built the confidence interval\n",
        " Lower extrem 1.0901973384384906\n",
        " Upper extreme 1.3871359948948425\n"
      ],
      "metadata": {
        "id": "FfhFwujcodhJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B) 99% Confidence Interval Using Known Population Standard Deviation\n",
        "\n",
        "If it were known that the population standard deviation is 0.2 million characters, construct a 99% confidence interval for the mean number of characters printed before failure.\n",
        "\n"
      ],
      "metadata": {
        "id": "2Ps-j2S1qEm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sigma = 0.2\n",
        "\n",
        "z_crit = stats.norm.ppf(0.995)\n",
        "\n",
        "# ME\n",
        "margin_of_error_known_sigma = z_crit * (sigma / np.sqrt(n))\n",
        "\n",
        "# CI\n",
        "ci_lower_known = mean - margin_of_error_known_sigma\n",
        "ci_upper_known = mean + margin_of_error_known_sigma\n",
        "\n",
        "print(f\"Lower Known {ci_lower_known}\\n Upper known {ci_upper_known}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhyJfXZXqArt",
        "outputId": "757a4874-cbb0-415f-bbb6-d2b59b84246f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower Known 1.1056514133957607\n",
            " Upper known 1.3716819199375725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation steps\n",
        "\n",
        "1: Used the same sample mean\n",
        "I already had the sample mean from earlier, so I reused that. The data and sample size remained the same, so nothing changed here.\n",
        "\n",
        "2: Population standard deviation is known\n",
        "This time, I was told that the population standard deviation is 0.2. That makes a big difference because when σ is known, we don’t need to estimate it from the sample. This allows us to use the z-distribution.\n",
        "\n",
        " 3: Chose the z-distribution\n",
        "Since σ is known, I used the z-distribution instead of the t-distribution. Even though the sample size is still small (n = 15), the key thing is that we now have the actual population standard deviation. That’s why the z-distribution is the correct choice.\n",
        "\n",
        " 4: Found the z-critical value\n",
        "For a 99% confidence interval, I needed the z-critical value that corresponds to 0.5% in each tail. The value comes out to approximately 2.576, which I used to calculate the margin of error.\n",
        "\n",
        "5: Calculated the margin of error\n",
        "Using the known population standard deviation, I calculated the margin of error. This gives the range above and below the sample mean that the true mean is likely to fall into.\n",
        " 6: Constructed the confidence interval\n",
        "Finally, I added and subtracted the margin of error from the sample mean to get the lower and upper bounds of the 99% confidence interval.\n",
        "\n",
        "Why z-distribution was used\n",
        "I used the z-distribution here because the population standard deviation was known. That makes the estimate of the mean more reliable, so the z-distribution (which has thinner tails than the t-distribution) is the proper choice.\n",
        "Also, using z results in a slightly narrower interval, since there’s less uncertainty when we know σ.\n"
      ],
      "metadata": {
        "id": "PrR8Z--oPkXs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rs7RRrd2QJLu"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}